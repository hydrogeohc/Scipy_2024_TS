{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Time Series Models Demo: Energy Consumption Forecasting\n",
    "\n",
    "This notebook provides a quick side-by-side comparison of different time series models for energy consumption forecasting.\n",
    "\n",
    "## Models Compared:\n",
    "1. **ARIMA** - Classical statistical approach\n",
    "2. **xLSTM** - Deep learning with explainability\n",
    "3. **AutoGluon** - AutoML ensemble approach\n",
    "\n",
    "## Evaluation Metrics:\n",
    "- MAE (Mean Absolute Error)\n",
    "- RMSE (Root Mean Squared Error)\n",
    "- Runtime (seconds)\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set style for better plots\n",
    "plt.style.use('seaborn-v0_8-darkgrid')\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Data Generation\n",
    "\n",
    "We generate synthetic energy consumption data with:\n",
    "- **Trend**: Linear upward trend\n",
    "- **Seasonality**: Annual seasonal pattern\n",
    "- **Noise**: Random fluctuations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_energy_data(n_samples=1000):\n",
    "    \"\"\"Generate synthetic energy consumption data with trend and seasonality\"\"\"\n",
    "    date_rng = pd.date_range(start='2020-01-01', periods=n_samples, freq='D')\n",
    "    df = pd.DataFrame(date_rng, columns=['timestamp'])\n",
    "    \n",
    "    # Create trend component\n",
    "    trend = np.linspace(0, 20, n_samples)\n",
    "    \n",
    "    # Create seasonal component (annual cycle)\n",
    "    season = 10 * np.sin(2 * np.pi * np.arange(n_samples) / 365.25)\n",
    "    \n",
    "    # Create random noise\n",
    "    noise = np.random.normal(0, 5, n_samples)\n",
    "    \n",
    "    df['energy_consumption'] = 100 + trend + season + noise\n",
    "    df.set_index('timestamp', inplace=True)\n",
    "    return df\n",
    "\n",
    "# Generate data\n",
    "np.random.seed(42)  # For reproducibility\n",
    "df = generate_energy_data()\n",
    "\n",
    "# Split into train and test\n",
    "test_size = 30\n",
    "train_data = df[:-test_size]\n",
    "test_data = df[-test_size:]\n",
    "\n",
    "print(f\"Dataset shape: {df.shape}\")\n",
    "print(f\"Training samples: {len(train_data)}\")\n",
    "print(f\"Test samples: {len(test_data)}\")\n",
    "\n",
    "# Visualize the data\n",
    "plt.figure(figsize=(14, 5))\n",
    "plt.plot(train_data.index, train_data['energy_consumption'], label='Training Data', alpha=0.7)\n",
    "plt.plot(test_data.index, test_data['energy_consumption'], label='Test Data', color='orange', alpha=0.7)\n",
    "plt.title('Energy Consumption Data', fontsize=14, fontweight='bold')\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Energy Consumption (kWh)')\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Model 1: ARIMA\n",
    "\n",
    "**Why ARIMA?**\n",
    "- Interpretable statistical model\n",
    "- Fast training on univariate data\n",
    "- Good baseline for comparison\n",
    "- Handles trend and seasonality explicitly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.tsa.arima.model import ARIMA\n",
    "from pmdarima import auto_arima\n",
    "\n",
    "print(\"Training ARIMA model...\")\n",
    "start_time = time.time()\n",
    "\n",
    "# Auto-select best parameters\n",
    "model_auto = auto_arima(train_data['energy_consumption'], \n",
    "                        start_p=0, start_q=0, max_p=5, max_q=5, m=7,\n",
    "                        start_P=0, seasonal=True, d=1, D=1, \n",
    "                        trace=False, error_action='ignore',\n",
    "                        suppress_warnings=True, stepwise=True)\n",
    "\n",
    "# Fit model\n",
    "model_arima = ARIMA(train_data['energy_consumption'], order=model_auto.order)\n",
    "results_arima = model_arima.fit()\n",
    "\n",
    "# Predict\n",
    "forecast_arima = results_arima.forecast(steps=test_size)\n",
    "\n",
    "arima_time = time.time() - start_time\n",
    "\n",
    "# Calculate metrics\n",
    "arima_mae = mean_absolute_error(test_data['energy_consumption'], forecast_arima)\n",
    "arima_rmse = np.sqrt(mean_squared_error(test_data['energy_consumption'], forecast_arima))\n",
    "\n",
    "print(f\"✓ ARIMA trained in {arima_time:.2f} seconds\")\n",
    "print(f\"  Best order: {model_auto.order}\")\n",
    "print(f\"  MAE: {arima_mae:.3f}\")\n",
    "print(f\"  RMSE: {arima_rmse:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Model 2: xLSTM (Simplified LSTM)\n",
    "\n",
    "**Why xLSTM?**\n",
    "- Captures complex non-linear patterns\n",
    "- Learns from sequential dependencies\n",
    "- More flexible than statistical models\n",
    "- Can incorporate multiple features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, LSTM\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "print(\"Training xLSTM model...\")\n",
    "start_time = time.time()\n",
    "\n",
    "# Prepare data\n",
    "scaler = MinMaxScaler()\n",
    "train_scaled = scaler.fit_transform(train_data[['energy_consumption']])\n",
    "test_scaled = scaler.transform(test_data[['energy_consumption']])\n",
    "\n",
    "# Create sequences\n",
    "def create_sequences(data, seq_length):\n",
    "    X, y = [], []\n",
    "    for i in range(len(data) - seq_length):\n",
    "        X.append(data[i:(i + seq_length)])\n",
    "        y.append(data[i + seq_length])\n",
    "    return np.array(X), np.array(y)\n",
    "\n",
    "seq_length = 30\n",
    "X_train, y_train = create_sequences(train_scaled, seq_length)\n",
    "\n",
    "# Build model\n",
    "model_lstm = Sequential([\n",
    "    LSTM(50, activation='relu', return_sequences=True, input_shape=(seq_length, 1)),\n",
    "    LSTM(50, activation='relu'),\n",
    "    Dense(1)\n",
    "])\n",
    "\n",
    "model_lstm.compile(optimizer=Adam(learning_rate=0.001), loss='mse')\n",
    "\n",
    "# Train\n",
    "history = model_lstm.fit(X_train, y_train, epochs=20, batch_size=32, \n",
    "                         validation_split=0.1, verbose=0)\n",
    "\n",
    "# Predict on test data\n",
    "# Use last seq_length points from training to start prediction\n",
    "last_sequence = train_scaled[-seq_length:]\n",
    "forecast_lstm = []\n",
    "\n",
    "for _ in range(test_size):\n",
    "    next_pred = model_lstm.predict(last_sequence.reshape(1, seq_length, 1), verbose=0)\n",
    "    forecast_lstm.append(next_pred[0, 0])\n",
    "    last_sequence = np.roll(last_sequence, -1, axis=0)\n",
    "    last_sequence[-1] = next_pred\n",
    "\n",
    "forecast_lstm = scaler.inverse_transform(np.array(forecast_lstm).reshape(-1, 1)).flatten()\n",
    "\n",
    "lstm_time = time.time() - start_time\n",
    "\n",
    "# Calculate metrics\n",
    "lstm_mae = mean_absolute_error(test_data['energy_consumption'], forecast_lstm)\n",
    "lstm_rmse = np.sqrt(mean_squared_error(test_data['energy_consumption'], forecast_lstm))\n",
    "\n",
    "print(f\"✓ xLSTM trained in {lstm_time:.2f} seconds\")\n",
    "print(f\"  MAE: {lstm_mae:.3f}\")\n",
    "print(f\"  RMSE: {lstm_rmse:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Model 3: AutoGluon-TimeSeries\n",
    "\n",
    "**Why AutoGluon?**\n",
    "- Automated model selection and ensembling\n",
    "- Combines multiple model types\n",
    "- Minimal hyperparameter tuning needed\n",
    "- Often achieves state-of-the-art results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from autogluon.timeseries import TimeSeriesDataFrame, TimeSeriesPredictor\n",
    "\n",
    "print(\"Training AutoGluon model...\")\n",
    "start_time = time.time()\n",
    "\n",
    "# Prepare data in AutoGluon format\n",
    "train_ag = pd.DataFrame({\n",
    "    'timestamp': train_data.index,\n",
    "    'target': train_data['energy_consumption'].values,\n",
    "    'item_id': ['energy'] * len(train_data)\n",
    "})\n",
    "\n",
    "train_ag = TimeSeriesDataFrame.from_data_frame(train_ag, id_column='item_id', timestamp_column='timestamp')\n",
    "\n",
    "# Train predictor\n",
    "predictor = TimeSeriesPredictor(\n",
    "    prediction_length=test_size,\n",
    "    target='target',\n",
    "    verbosity=0\n",
    ")\n",
    "\n",
    "predictor.fit(\n",
    "    train_ag,\n",
    "    presets='fast_training',  # Use fast preset for demo\n",
    "    time_limit=60  # Limit training time\n",
    ")\n",
    "\n",
    "# Predict\n",
    "forecast_ag = predictor.predict(train_ag)\n",
    "forecast_autogluon = forecast_ag['mean'].values\n",
    "\n",
    "autogluon_time = time.time() - start_time\n",
    "\n",
    "# Calculate metrics\n",
    "autogluon_mae = mean_absolute_error(test_data['energy_consumption'], forecast_autogluon)\n",
    "autogluon_rmse = np.sqrt(mean_squared_error(test_data['energy_consumption'], forecast_autogluon))\n",
    "\n",
    "print(f\"✓ AutoGluon trained in {autogluon_time:.2f} seconds\")\n",
    "print(f\"  MAE: {autogluon_mae:.3f}\")\n",
    "print(f\"  RMSE: {autogluon_rmse:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Results Comparison\n",
    "\n",
    "### Summary Metrics Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create comparison DataFrame\n",
    "results = pd.DataFrame({\n",
    "    'Model': ['ARIMA', 'xLSTM', 'AutoGluon'],\n",
    "    'MAE': [arima_mae, lstm_mae, autogluon_mae],\n",
    "    'RMSE': [arima_rmse, lstm_rmse, autogluon_rmse],\n",
    "    'Runtime (s)': [arima_time, lstm_time, autogluon_time]\n",
    "})\n",
    "\n",
    "# Add relative performance\n",
    "results['MAE (% of best)'] = (results['MAE'] / results['MAE'].min() * 100).round(1)\n",
    "results['Runtime (% of fastest)'] = (results['Runtime (s)'] / results['Runtime (s)'].min() * 100).round(1)\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"MODEL COMPARISON SUMMARY\")\n",
    "print(\"=\"*70)\n",
    "print(results.to_string(index=False))\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Highlight best performer\n",
    "best_mae_idx = results['MAE'].idxmin()\n",
    "best_rmse_idx = results['RMSE'].idxmin()\n",
    "fastest_idx = results['Runtime (s)'].idxmin()\n",
    "\n",
    "print(f\"\\n✓ Best MAE: {results.loc[best_mae_idx, 'Model']}\")\n",
    "print(f\"✓ Best RMSE: {results.loc[best_rmse_idx, 'Model']}\")\n",
    "print(f\"✓ Fastest: {results.loc[fastest_idx, 'Model']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visual Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot all forecasts together\n",
    "fig, axes = plt.subplots(2, 2, figsize=(16, 10))\n",
    "\n",
    "# Plot 1: All forecasts overlaid\n",
    "ax = axes[0, 0]\n",
    "ax.plot(test_data.index, test_data['energy_consumption'], \n",
    "        label='Actual', color='black', linewidth=2, marker='o', markersize=4)\n",
    "ax.plot(test_data.index, forecast_arima, \n",
    "        label=f'ARIMA (MAE={arima_mae:.2f})', alpha=0.7, linewidth=2)\n",
    "ax.plot(test_data.index, forecast_lstm, \n",
    "        label=f'xLSTM (MAE={lstm_mae:.2f})', alpha=0.7, linewidth=2)\n",
    "ax.plot(test_data.index, forecast_autogluon, \n",
    "        label=f'AutoGluon (MAE={autogluon_mae:.2f})', alpha=0.7, linewidth=2)\n",
    "ax.set_title('Forecast Comparison', fontsize=12, fontweight='bold')\n",
    "ax.set_xlabel('Date')\n",
    "ax.set_ylabel('Energy Consumption (kWh)')\n",
    "ax.legend()\n",
    "ax.grid(True, alpha=0.3)\n",
    "\n",
    "# Plot 2: MAE Comparison\n",
    "ax = axes[0, 1]\n",
    "bars = ax.bar(results['Model'], results['MAE'], color=['#1f77b4', '#ff7f0e', '#2ca02c'])\n",
    "ax.set_title('Mean Absolute Error (Lower is Better)', fontsize=12, fontweight='bold')\n",
    "ax.set_ylabel('MAE')\n",
    "for i, bar in enumerate(bars):\n",
    "    height = bar.get_height()\n",
    "    ax.text(bar.get_x() + bar.get_width()/2., height,\n",
    "            f'{height:.2f}', ha='center', va='bottom', fontweight='bold')\n",
    "ax.grid(True, alpha=0.3, axis='y')\n",
    "\n",
    "# Plot 3: RMSE Comparison\n",
    "ax = axes[1, 0]\n",
    "bars = ax.bar(results['Model'], results['RMSE'], color=['#1f77b4', '#ff7f0e', '#2ca02c'])\n",
    "ax.set_title('Root Mean Squared Error (Lower is Better)', fontsize=12, fontweight='bold')\n",
    "ax.set_ylabel('RMSE')\n",
    "for i, bar in enumerate(bars):\n",
    "    height = bar.get_height()\n",
    "    ax.text(bar.get_x() + bar.get_width()/2., height,\n",
    "            f'{height:.2f}', ha='center', va='bottom', fontweight='bold')\n",
    "ax.grid(True, alpha=0.3, axis='y')\n",
    "\n",
    "# Plot 4: Runtime Comparison\n",
    "ax = axes[1, 1]\n",
    "bars = ax.bar(results['Model'], results['Runtime (s)'], color=['#1f77b4', '#ff7f0e', '#2ca02c'])\n",
    "ax.set_title('Training Runtime (Lower is Better)', fontsize=12, fontweight='bold')\n",
    "ax.set_ylabel('Time (seconds)')\n",
    "for i, bar in enumerate(bars):\n",
    "    height = bar.get_height()\n",
    "    ax.text(bar.get_x() + bar.get_width()/2., height,\n",
    "            f'{height:.1f}s', ha='center', va='bottom', fontweight='bold')\n",
    "ax.grid(True, alpha=0.3, axis='y')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('results/model_comparison.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"\\n✓ Comparison plot saved to 'results/model_comparison.png'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Key Takeaways\n",
    "\n",
    "### Design Choices & Rationale:\n",
    "\n",
    "1. **Test Size (30 days)**: Chosen to balance evaluation robustness with computational efficiency\n",
    "2. **Sequence Length (30 for LSTM)**: One month of history provides sufficient context for patterns\n",
    "3. **Model Selection**:\n",
    "   - **ARIMA**: Baseline for interpretability and speed\n",
    "   - **xLSTM**: Deep learning for complex pattern capture\n",
    "   - **AutoGluon**: State-of-the-art automated approach\n",
    "\n",
    "### Evaluation Strategy:\n",
    "- **MAE**: Easier to interpret (average error in kWh)\n",
    "- **RMSE**: Penalizes large errors more heavily\n",
    "- **Runtime**: Important for production deployment\n",
    "\n",
    "### Trade-offs:\n",
    "- **Speed vs Accuracy**: ARIMA is fastest but may sacrifice accuracy\n",
    "- **Interpretability vs Performance**: Neural networks are less interpretable\n",
    "- **Complexity vs Maintainability**: AutoGluon automates complexity but is a black box\n",
    "\n",
    "---\n",
    "\n",
    "**Next Steps**: For production deployment, consider:\n",
    "1. Hyperparameter tuning for the best-performing model\n",
    "2. Cross-validation for more robust evaluation\n",
    "3. Feature engineering (weather, holidays, etc.)\n",
    "4. Ensemble methods combining multiple models"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
